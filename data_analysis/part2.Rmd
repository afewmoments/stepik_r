---
title: "data_analysis"
output: html_document
editor_options: 
  chunk_output_type: console
---

# Этап 2

## Используемые библиотеки

```{r}
library(tidyverse)
library(data.table)
```

## Функции семейства apply

### Основы

Возьмём встроенный набор данных

```{r}
data(diamonds)
str(diamonds)
```

Посмотрим минимальный размерность для каждого бриллианта

Через цикл:

```{r}
min_size <- c()

for (i in 1:nrow(diamonds)) {
  min_size <- c(min_size, min(diamonds[i, 8:10]))
}

head(min_size)
```

Это очень долго, в силу особенностей языка R. Можно ускорить, если сообщить какой тип данных будет у вектора, и сколько там будет значений. На каждом этапе сейчас мы перезаписываем.

```{r}
min_size <- c(nrow(diamonds))

for (i in 1:nrow(diamonds)) {
  min_size[i] <- min(diamonds[i, 8:10])
}
```

Теперь разберём правильный код. На всём протяжении работы с данными, мы будем применять к данным какие-то функции. Поэтому apply становится незаменимым фреймворком

```{r}
min_size <- apply(diamonds[, 8:10], 1, min) # 1 -- работая со строчками
```

Задача решена в одну строчку и очень быстро.

### Как работает

```{r}
apply(X, margin, ...)
```

X --- данные

MARGIN --- как рименяем функцию, по строчкам или по столбцам

FUN --- какая функция применяется

Потренируемся.

```{r}
d <- matrix(rnorm(30), nrow = 5)

apply(d, 1, sd)
```

apply взяла первую строчку данных, применила к ним sd. Потом вторую, и т.д. до конца.


```{r}
apply(d, 2, sd)
```

Всё тоже самое --- только к колнкам

#### Задача

В переменной d сохранен dataframe с произвольным числом количественных переменных. При помощи функции apply найдите максимальное значение в каждой строке. Сохраните результат (вектор максимальных значений) в переменную row_max.

```{r}
row_max <- apply(d, 1, max)
```

### Как работает, продолжение

Если функция возвращает одно значение по результатам работы, то мы получаем вектор длинной по кол-ву строк или столбцов. Но что если функция возврщает несколько значений. Допустим функция range --- максимум и минимум

```{r}
my_range <- apply(d, 2, range)
```

Мы получаем не вектор, а матрицу.

А что если функция возвращает разное кол-во данных. Например Функция которая выводит только выбросы

```{r}
outliers_count <- function(x){
  outliers <- x[abs(x - mean(x)) > 2 * sd(x)]
  if (length(outliers) > 0) {
    return(outliers)
  } else {
    return("There are no outliers")
  }
}
```

Посмотрим есть ли выбросы в данных iris

```{r}
iris_num <-  iris[, 1:4]

apply(iris_num, 2, outliers_count)
```

Так как длины разные, то выходная запись --- лист с данными.

Apply --- инструмент, который хорошо заменяет цикл for.

### Многоточие

Через многоточие можно передавать аргументы используемой функции

```{r}
head(airquality)

apply(airquality, 2, mean)
```

Работает вот так

```{r}
apply(airquality, 2, mean, na.rm = T)
```

### Компактная функция --- можно прописывать функцию в теле apply

```{r}
set.seed(42)

d <- as.data.frame(matrix(rnorm(30), nrow = 5))

my_fun <- function(x) x * 2

```

Такая функция нигде не засветится.

Внутри функции apply можно записывать функцию. Это короткая функция

```{r}
apply(d, 2, function(x) x[x < 0])
```

#### Задача

Давайте завершим и слегка модифицируем задачу из предыдущей лекции. Напишите функцию get_negative_values, которая получает на вход dataframe произвольного размера. Функция должна для каждой переменной в данных проверять, есть ли в ней отрицательные значения. Если в переменной отрицательных значений нет, то эта переменная нас не интересует, для всех переменных, в которых есть отрицательные значения мы сохраним их в виде списка или матрицы, если число элементов будет одинаковым в каждой переменной (смотри пример работы функции).

```{r}
test_data <- as.data.frame(list(V1 = c(NA, -0.5, -0.7, -8), V2 = c(-0.3, NA, -2, -1.2), V3 = c(1, 2, 3, NA)))

get_negative_values <- function(test_data){    
negative_col <- apply(test_data, 2, function(x) any(x[!is.na(x)] < 0))    
return(apply(test_data[negative_col], 2, function(x) x[!is.na(x) & x <0]))}
```

### Продолжение

Можно было бы применить дисперсионный анализ

```{r}
head(iris)
aov(Sepal.Length ~ Species, data = iris)
```

Но это делается только по одной переменной, давайте сделаем это для всех переменных
Берем только количественные перменные

```{r}
aov_result <- apply(iris[, 1:4], 2, function(x) aov(x ~ iris$Species))

norm_test <- apply(iris[, 1:4], 2, 
                   function(x) shapiro.test(x))


# Сразу достаём p.value
norm_test_p <- apply(iris[, 1:4], 2, 
                   function(x) shapiro.test(x)$p.value)

```

Этот код сделает сравнение трёх групп между собой по всем количественным перменным

Применяем статистический тест к нескольким параметрам

Для второй части по статистике --- p-уровень значимость

#### Задача

Напишите функцию na_rm которая заменяет все пропущенные значения в столбцах dataframe на соответствующее среднее значение. То есть все NA в первом столбце заменяются на среднее значение первого столбца (рассчитанного без учета NA). Все NA второго столбца заменяются на среднее значение второго столбца и т.д.  Замена пропущенных значений на среднее. change NA to mean

Функция na_rm на вход получает dataframe произвольной размерности, состоящий из количественных переменных. Функция должна возвращать  dataframe с замененными NA. Ни порядок столбцов, ни порядок строк в dataframe изменять не нужно.

Вы можете создавать вспомогательные функции для решения этой задачи. 

```{r}
test_data <- as.data.frame(list(V1 = c(NA, NA, NA, NA, 13, 12, 9, 10, 8, 9, 11, 11, 10, 12, 9), V2 = c(NA, 12, 8, NA, 11, 11, 9, 8, 8, 10, 10, 11, 10, 10, 10), V3 = c(NA, 5, NA, 13, 12, 11, 11, 14, 8, 12, 8, 8, 10, 10, 8), V4 = c(10, 10, 10, 10, 13, 10, 11, 7, 12, 10, 7, 10, 13, 10, 9)))


na_rm <- function(x){
  result <- apply(x, 2, function(y){
  y[is.na(y)] <- mean(y, na.rm=T)
  return(y)
  })
  return(as.data.frame(result))
}

na_rm(test_data)

# Решение через ifelse

na_rm <- function(x){
  y <- apply(x,2,function(x) ifelse(is.na(x),mean(x,na.rm=T),x))
  return(as.data.frame(y))}

```

### lapply, sapply, tapply, by, vapply, mapply

В чём основная идея --- применяем некоторую функцию к объекту.

Почему их много? Потому что у apply  есть особенности:

* apply  нельзя применить к вектору, или дата.фрейму, списку

Для списков есть lapply

```{r}
my_list <- list(x = c(rnorm(30), NA), y = rnorm(10))
str(my_list)

#  она чувствительна к выбросам
lapply(my_list, mean) 

#  но можно так же через ... протаскивать аргументы функции
lapply(my_list, mean, na.rm = T)

#  основные идеи такие же --- можно писать функцию
lapply(my_list, function(x) x * 2)
```

Отличие 

* lapply всегда возвращает список той же длинны что и на входе.

* sapply упрощает вывод, пытается вернуть либо в виде вектора, либо в виде матрицы. И только если не получилось, возвращает в виде списка

```{r}
sapply(my_list, range, na.rm = T)
sapply(my_list, range, na.rm = T, simplify = F)
```

#### Задача

Напишите функцию positive_sum, которая получает на вход dataframe с произвольным количеством числовых переменных. Основная задача функции - найти сумму положительных значений в каждой переменной и сохранить их в список. Рассмотрим пример работы функции на небольшом примере:

Моё решение:

```{r}
positive_sum <- function(d){
  d <- apply(d, 2, function(x)(ifelse(x > 0, x, 0)))
  d <- as.data.frame(d)
  lapply(d, sum, na.rm = T)
}

positive_sum(d)
```

Гораздо более изящное решение, суммирование по индексам:

```{r}
positive_sum <- function(d) {
  lapply(d, function(x) sum(x[x>0], na.rm = T))
  }
```

### Практическая особенность sapply

Эти функции можно применять к вектору.

Есть задача, есть вектор с именами cars и есть какая-то машина с точным названием. Мы хотим понять, есть ли какая-то машина в векторе cars с таким же названием как и искомая машина

```{r}
cars <- c("Mazda", "Volga", "Merc")
car <- c("Mazda RX4")
```

Просто поэлементное сравнение ничего не даст. Но есть функция grepl(). Она проверяет, содержится ли первый вектор во втором

```{r}
grepl("Mazda", "Mazda RX4")
```

Наша задача понять является этот элемент 

```{r}
sapply(cars, function(x) grepl(x, car))
```

Так как это логический вектор, его можно использовать в качестве индексации

```{r}
cars[sapply(cars, function(x) grepl(x, car))]
```

Обратите внимание на следующее выражение, которое очень часто будет вам помогать при работе с данными:

давайте напишем команду, которая отбирает только количественные колонки в данных:

```{r}
iris_num <- iris[sapply(iris, is.numeric)]
```

Готово! sapply(iris, is.numeric) возвращает вектор логических значений, который мы и используем для индексации.

Этот пример также иллюстрирует идею, что lapply и sapply можно применять к dataframe. Так как dataframe - это в том числе и список.

Например, результат команды:

```{r}
sapply(iris[1:4], sd)
```

эквивалентна результату: 

```{r}
apply(iris[1:4], 2, sd)
```

так как каждая колонка dataframe - это и есть элемент списка, то функция lapply и sapply возвращает результат применения некоторой функции к каждой колонке данных!
Но тут есть одно но!

Как вы помните, apply производит все опперации именно над матрицами, поэтому если вы отправите в apply dataframe с разными типами данных, то R сначала приведет все колонки к одному типу, чтобы получилась матрица, т.к. в матрице могут храниться данные только одного типа! Это в свою очередь может привести к неожиданному результату:

```{r}
sapply(iris, is.numeric)

apply(iris, 2, is.numeric)
```

По результатам команды apply можно подумать, что в данных нет количественных переменных! Дело в том, что перед тем как применить функцию is.numeric, сначала данные iris были переведены в матрицу, а все переменные переведены в строки, как в наиболее общий тип данных. В результате получаем для каждой колонки FALSE.

Вот такой вот тонкий момент, о котором нужно помнить, применяя функцию apply к data.frame. В свою очередь с sapply и lapply такого не случится, т.к. в этом случае мы по очереди применим требуемую функцию к каждой колонке данных, как к каждому элементу списка! 

### Функция tapply. Спойлер --- aggregate лучше

Они не так встречаются. На вход принимает вектор, группирует по какому-то индексу, и применяет к этим группам функцию

```{r}
tapply(mtcars$mpg, mtcars$am, mean)
```

У этой функции есть более удобный аналог, функция aggregate

```{r}
aggregate(mpg ~ am, mtcars, mean)
```

Есть ещё функция by, которая группирует переменные

```{r}
by(iris[1:4], iris$Species, colMeans)
```

Как работает эта функция --- она берёт датафрейм ирис, и разбивает на несколько датафреймов в зависимости от перменной Species. Внутри функции by мы должны писать только те функции которые применимы к датафрейму

Можно к примеру написать такую функцию, которая проверяет на нормальность каждую количественную переменную, в зависимости от группирующей переменной.

```{r}
by(iris[1:4], iris$Species, 
   function(x) sapply(x, 
                      function(col) shapiro.test(col)$p.value))
```

Но не стоит на ней заостряться, функционал можно воспроизвести при помощи aggregate

```{r}
aggregate(. ~ Species, iris, function(x) shapiro.test(x)$p.value)
```

### Функция vapply

Такая же как lapply, только мы заранее говорим что хотим получить на выходе

```{r}
vapply(mtcars, mean, FUN.VALUE = numeric(1))
sapply(mtcars, mean)
```

Мы сообщаем на выходе, что хотим получить. Это ускоряет чисто вычислительный процесс

### Функция mapply

Она последовательно берёт элементы двух векторов и посылает их в функцию.

```{r}
mapply(rep, c(1, 2, 3, 4), c(1, 2, 3, 4))

rep(1, 3)
x <- c(20, 25, 13)
m <- c(0, 1, 2)
s <- c(3, 5, 6)
mapply(rnorm, x, m, s)
```


Допустим у нас есть матрица размером 100 на 200:

```{r}
m <- matrix(rnorm(100 * 200), nrow = 100)
```

И мы хотим присвоить имена строчкам и столбикам в этой матрице по принципу:

row_1, row_2, row_3, ..., row_100 - для строк

col_1, col_2, col_3, ..., col_200 - для колонок

Тогда мы могли бы сгенерировать список данными именами следующим образом:

```{r}
m_names <- mapply(paste, list("row", "col"), list(1:100, 1:200), sep = "_")
str(m_names)
```

### Подводный камень

Хотелось бы рассмотреть еще один подводный камень применения функций семейства apply к dataframe.

Предположим, мы решили написать простенькую функцию для расчета стандартного отклонения количественных переменных в данных.

```{r}
get_sd <- function(x){
  num_var <- sapply(x, is.numeric)
  sapply(x[, num_var], sd)
}
```

Казалось бы, все логично и работает на различных примерах:

```{r}
get_sd(iris)
```

Но в нашем коде скрыта серьезная уязвимость!) Предположим, у нас есть набор данных, в котором только одна количественная переменная:

```{r}
my_df <- data.frame(x = 1:10, y = letters[1:10])
get_sd(my_df)
```

Что вообще только что произошло? Дело в том, что существуют различные способы обращения к колонкам dataframe:

my_df[1] - получим dataframe

my_df[[1]] - получим вектор

my_df[, 1] - получим вектор

В случае, если у нас только одна количественная переменная, обращение x[, num_var] вернет колонку в виде вектора, а sapply применит функцию sd к каждому наблюдению вместо того, чтобы применить ко всей переменной.

Таким образом, если вы хотите применить какую-либо функцию к неизвестному заранее числу колонок в данных, лучше используйте такую индексацию типа: my_df[col_index]. То есть:

```{r}
get_sd <- function(x){
  num_var <- sapply(x, is.numeric)
  sapply(x[num_var], sd)}> get_sd(my_df)
```

также можно использовать параметр drop = FALSE при индексации (x[,num_var, drop = FALSE)

### Задача

Предположим у нас есть dataframe с двумя переменными name - название гена, expression - уровень экспрессии. Например:

```{r}
test_data <- as.data.frame(list(name = c("p4@HPS1", "p7@HPS2", "p4@HPS3", "p7@HPS4", "p7@HPS5", "p9@HPS6", "p11@HPS7", "p10@HPS8", "p15@HPS9"), expression = c(118.84, 90.04, 106.6, 104.99, 93.2, 66.84, 90.02, 108.03, 111.83)))

names = c("HPS5", "HPS6", "HPS9", "HPS2", "HPS3", "HPS7", "HPS4", "HPS8")
```

Обратите внимание, что само название гена спрятано внутри строки и указано после символа @. Напишите функцию my_names, которая получает на вход  датафрейм и вектор с именами тех генов, для которых мы хотим отобрать наблюдения уровня экспрессии. Допустим, мы хотим отобрать наблюдения только для генов 'HPS1' и 'GOT1', тогда результат работы функции будет следующий:

выстрадал решение:

```{r}
my_names <- function (dataset, names){
  t <- sapply(names, function(x) which(grepl(x, dataset[, 1])))
  dataset[as.vector(t), ]
}

my_names(test_data, names)
```

Как работает функция:

* grepl(x, dataset[, 1]) --- ищет совпадение задаваемой строки в первом столбце заданных данных и возвращает матрицу, в которой на месте пересечения входа X в строку dataset[, 1] стоит TRUE

* sapply(names, function(x) which(grepl(x, dataset[, 1]))) --- возврщает номера строк TRUE, в которых было пересечение X  с dataset[, 1] 

*  dataset[as.vector(t), ] по индексу берём все строки, удовлетворяющие условию

### Задача

Задачка посерьезнее! Друзья, это задание действительно сложное, если не удается его решить, не печальтесь, пройдите курс дальше, вооружитесь новыми знаниями, например, вот этими или этими, вы всегда можете вернуться к этому заданию! Спойлер: решение всего-то в четыре строчки!)

Напишите функцию find_outliers, которая получает на вход dataframe с одной количественной переменной и произвольным числом факторных переменных. Факторные переменные разбивают все наши наблюдения на определенное число групп. Например, если мы посмотрим на данные mtcars и возьмем в качестве группирующих переменных: am - две градации и cyl три градации, то получим 6 групп наблюдений на пересечении градаций этих переменных. Рассчитаем, к примеру, средние в каждой из шести групп:

```{r}
aggregate(mpg ~ cyl + am, mtcars, mean)

test_data <- read.csv("https://stepic.org/media/attachments/course/724/hard_task.csv")
head(test_data)
str(test_data)

correct_answer <- read.csv("https://stepic.org/media/attachments/course/724/hard_task_ans.csv")
head(correct_answer)
str(correct_answer)

```

Итак, ваша задача — создать в данных новую числовую переменную is_outlier, которая будет принимать значение 1, если наблюдение в этой строке является выбросом в своей группе, и 0, если не является.

Под выбросами будем понимать наблюдения, отклоняющиеся от среднего значения в группе более чем на два стандартных отклонения этой группы. 

Поясню условие на примере данных ToothGrow. Сначала переведем группирующие переменные в фактор. Одна из группирующих переменных имеет  две градации, другая три, значит все наши наблюдения разбиваются на шесть групп. Ваша задача проанализировать каждую группу и отметить там выбросы, если они есть. Иными словами, сначала мы берем все наблюдения для которых supp = VC и dose = 0.5. В этой группе смотрим, есть ли наблюдения, у которых значения len отклоняются от среднего в этой группе больше чем на два sd. И так повторяем для оставшихся трех групп. В итоге в новой переменной is_outlier будет храниться информация - является ли наблюдение выбросом не по всем данным, а только в своей группе.

А также: порядок переменных является случайным, единственная количественная переменная может быть первым столбцом, может последним и т.д.

```{r}
find_outliers <- function(t){
  # ищем колчиественную переменную, и записываем её в var_name
  var_name <- colnames(t[sapply(t, is.numeric)])
  # группируем данные по факторным переменным
  t <- group_by_at(t, vars(one_of(colnames(t[sapply(t, is.factor)]))))
  # вводим переменную is_outlier
  t <- mutate(t, is_outlier = ifelse(abs(get(var_name) - mean(get(var_name))) > 2 * sd(get(var_name)), 1,0)) 
  return(t)
}

ToothGrowth$dose <- factor(ToothGrowth$dose)
find_outliers(ToothGrowth)
```

Данная задачка — не праздное развлечение, чаще всего мы проверяем распределение на нормальность именно в контексте нескольких групп, а не по всей переменной в целом. Наша функция, создав новую переменную, позволит сделать по этой переменной subset и убрать все выбросы:

```{r}
ToothGrowth  <- find_outliers(ToothGrowth)
clear_data <- subset(ToothGrowth, is_outlier == 0)
```

### Задача

Перейдем от этапа предобработки данных к применению уже знакомых нам статистических критериев. Кстати, если вы еще не решали практические задачи из курса Основы статистики. Часть два, рекомендую вам обратить на них внимание. В конце каждого модуля есть подборка практических задач, решение которых, поможет вам закрепить пройденный в этом модуле материал.

Типичная задача, с которой мы сталкиваемся при анализе данных - это исследование большого числа переменных и их взаимосвязей между собой. Умение алгоритмизировать рутинные операции сэкономит вам массу времени. 

Рассмотрим следующую ситуацию: у нас есть dataframe с произвольным числом количественных переменных. Мы хотим построить линейную регрессию для предсказания значений зависимой переменной, однако, в качестве предикторов мы хотим использовать только те переменные, распределение которых значимо не отличается от нормального (p - value теста Шапиро - Уилка больше 0.05).

Напишите функцию smart_lm, которая получает на вход data.frame с произвольным числом количественных переменных. Первая колонка в данных - это зависимая переменная, все остальные - предикторы. На первом этапе вы должны отобрать предикторы для модели. 

Функция возвращает в виде вектора коэффициенты линейной регрессии построенной только для отобранных предикторов (условие нормальности распределения). Если таких предикторов в данных не оказалось, то функция возвращает предупреждение "There are no normal variables in the data".

Перед тем как сдавать код, советую убедиться, что вы прошли такие тесты как:

```{r}
smart_lm <- function(df){
  # Сначала проверяем особые случаи, когда переменных две
  if(length(df) == 2){
    # Если переменные две, то проверяем вторую переменную на нормальность. Если она нормальна, выводим коэффициенты
    # Если нет, то выводим предупреждение
    if(shapiro.test(df[, 2])$p.value > 0.05){
  lm(df[,1] ~ df[,2], df)$coefficients
} else {
  return("There are no normal variables in the data")
}
    # Если переменных больше, то удаляем первую переменную (она будет предикантом)
    } else {
      t <- df[, -1]
      # Записываем во фрейм данных только нормальные переменные
      s <- t[sapply(t, function(x) shapiro.test(x)$p.value) > 0.05]
      # Делаем проверку, если вектор не пустой, значит там есть нормальные переменные
      if(length(s) > 0){
        # Через функцию as.formula записываем формулу, в которой перечисляем все названия нормальных переменных
        fmla <- as.formula(paste("depend ~ ", paste(colnames(s), collapse = "+")))
        #  Добавляем во фрейм данных изначально удалённую зависимую переменную
        s <- mutate(s, depend =  df[, 1])
        # Возвращаем коэффициенты линейной модели
        return(lm(fmla, s)$coefficients)
        # Если вектор пустой, выводим предупреждение
        } else {
          return("There are no normal variables in the data")
      }
    }
  }
```

Вот более элегантное решение. Здесь не вводится формула, её заменяет точка "."

```{r}
smart_lm <- function(x){    
check_norm <- sapply(x[-1], function(var) shapiro.test(var)$p.value > 0.05)    
if (any(check_norm)){    
x = x[, c(1, (which(check_norm) + 1))]    
coef <- lm(x[[1]] ~ ., x[-1])$coef    
return(coef)    
} else{    
return('There are no normal variables in the data')}}
```

### Задача

Иногда возникает необходимость применить какой-либо критерий к большому числу количественных переменных. В этой задаче мы используем выборочный t - test, который сравнивает выборочное среднее с предполагаемым средним в генеральной совокупности.  

Напишите функцию one_sample_t, которая получает на вход два аргумента:

1. Dataframe произвольного размера с произвольным числом переменных различного типа.

2. Числовое значение среднего в генеральной совокупности.

Ваша функция должна применять одновыборочный t - test к каждой числовой переменной в данных, и сравнивать среднее значение этой переменной с указанным значением среднего в генеральной совокупности (второй аргумент функции).

Функция должна возвращать список, где каждый элемент это вектор, состоящий из t - значения, числа степеней свобод (df) и значения p - value.

```{r}
one_sample_t <- function(test_data, general_mean){
  # отбираем только числовые переменные
  numeric_data <- test_data[sapply(test_data, is.numeric)]
  # к числовым переменным применяем t.test и отбираем интересующие параметры
  # выводим списком, как это требуется в задании
  lapply(numeric_data, function(x) c(t.test(x, mu = general_mean)$statistic, 
                                     t.test(x, mu = general_mean)$parameter, 
                                     t.test(x, mu = general_mean)$p.value))
  }
```

Фактически всё тоже самое, но в более элегантной форме:

```{r}
one_sample_t <- function(data, mean) {
    lapply(data[sapply(data, is.numeric)],
           function(x) unlist(t.test(x, mu = mean)[c("statistic", "parameter", "p.value")]))
}
```

### Задача

Итак, ваша задача, написать функцию get_p_value, которая получает на вход список (назовем его главным списком), каждый элемент этого списка тоже список - результат выполнения функции shapiro.test (смотри пример normality_tests). Ваша задача из каждого элемента главного списка вытащить только p - value. В итоге функция возвращает список где каждый элемент - одно значение - p - value (как в примере normality_tests_p).

```{r}
get_p_value <- function(test_list){
  lapply(test_list, function(x) x$p.value)
}
```

## Работа с данными при помощи dplyr

Уже знакомая библиотека, которую мы уже знаем.
 
```{r}
my_data <- data_frame(x = rnorm(10000), y = rnorm(10000), 
                      f = factor(rep(1:2, 5000)))

# а ниже классический дата.фрейм
my.data <- data.frame(x = rnorm(10000), y = rnorm(10000), 
                      f = factor(rep(1:2, 5000)))
```

В чём различия? 

* dplyr --- прерывает излишний вывод, и выводит тип данных

* dplyr --- разрешает называть перменные с пробелами

* dplyr --- разрешает использовать функции внутри функции

```{r}
my_data_2 <- data_frame(x = rnorm(10), y = abs(x))
# my.data.2 <- data.frame(x = rnorm(10), y = abs(x))  не работает
```

### Работа с колонками и строками 

* select --- позволяет отобрать колонки

* slice --- позволяет отобрать строки


```{r}
select(diamonds, 1, 2, 3)
diamonds[c("cut", "price", "color")]

# Можно  обращаться к столбцам которые содержат t
select(diamonds, contains("t"))

# step 6 slice rows
slice(diamonds, c(1, 4, 5))
diamonds[c(1, 4, 5)]
```

###  Функция filter

```{r}
filter(diamonds, carat > 0.3 | color == "J")
diamonds[diamonds$carat > 0.3 & diamonds$color == "J", ]
subset(diamonds, carat > 0.3 & color == "J")
```

###  Функция arrange --- сортировка

```{r}
arrange(diamonds, desc(price))
diamonds[order(diamonds$price, diamonds$depth), ]
```

###  Функция rename и mutate

Тоже уже знакомы

#### Задача

Давайте потренируемся обращаться к данным. Вы можете использовать базовый синтаксис, функции из пакета dplyr или data.table. 

Поработаем с данными diamonds из пакета ggplot2. 

В переменную d сохраните только нeчетные строчки исходных данных diamonds. 

Обратите внимание на функцию seq(). Она может вам пригодиться вам не только в этой задаче.

```{r}
d <- slice(diamonds, seq(1, nrow(diamonds), 2))
```

#### Задача

Потренируемся использовать изученные функции. Из данных mtcars отберите только четыре переменные: mpg, hp, am, vs. 
Оставьте только те наблюдения, для которых значения mpg > 14 и hp > 100. 
Отсортируйте получившиеся данные по убыванию переменной mpg и возьмите только первые 10 строчек. 
Переменную mpg переименуйте в Miles per gallon, а переменную hp в  Gross horsepower (обратите внимание, dplyr позволит нам создать пременные с пробелами в названии). Получившийся dataframe сохраните в переменную my_df. 

```{r}
my_df <- mtcars %>% 
  select(mpg, hp, am, vs) %>% 
  filter(mpg > 14 & hp > 100) %>% 
  arrange(desc(mpg)) %>% 
  slice(1:10) %>% 
  rename("Miles per gallon" = mpg,
         "Gross horsepower" = hp)
mtcars %>% 
  slice(1:10)
```

## Работа с данными при помощи dplyr продолжение

Есть полезная функция mutate_each

```{r}
d <- as_data_frame(matrix(rnorm(30), ncol = 5))

mutate_each(d, funs(ifelse(. < 0, 0, .)))
```

В funs --- точка «.» означает колонку данных
Мы применяем для каждой колонке данных применим функцию. Её преимуществом является то, что она возвращает датафрейм

#### Задача

Напишите функцию, all_to_factor, которая преобразует dataframe, переводя все его переменные в фактор.

```{r}
all_to_factor <- function(x){
  mutate_each(x, funs(as.factor(.)))
}

all_to_factor(mtcars)
```

#### Задача

В этом задании от вас потребуется написать функцию для предобработки данных log_transform. В статистике часто трансформируют исходные переменные. Например, используют значение натурального логарифма исходной переменной.

Ваша задача написать функцию, которая получает на вход dataframe  с произвольным числом переменных разных типов. На первом этапе функция должна выполнить предобработку числовых переменных. Т.к. значение логарифма мы можем рассчитать только для положительных чисел. Для этого сделаем центрирование всех переменных (Rescaling), только еще добавим единичку, чтобы у нас не осталось нулей:

После того как мы масштабировали каждую переменную, осталось рассчитать значение натурального логарифма каждого наблюдения (функция log) и вернуть новый dataframe. 

```{r}
test_data <- data_frame(V1 = rnorm(5),
                        V2 = rnorm(5),
                        V3 = rnorm(5),
                        V4 = c("A","B","B","B","B"))


log_transform <- function(test_data){      
rescaling <- function(x){      
log((x - min(x)) / (max(x) - min(x)) + 1)}      
num_var <- sapply(test_data, is.numeric)      
test_data[num_var] <- mutate_each(test_data[num_var], funs(rescaling))      
return(test_data)}



log_transform <- function(test_data){
test_data %>% mutate_if(is.numeric, funs(log(((. - min(.)) /(max(.) - min(.))) + 1)))
}


```

